{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandanmahato624/ai-chat-system/blob/master/new_next_word_lstm_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrmA3eaj3kF0"
      },
      "outputs": [],
      "source": [
        "faqs = \"\"\"Mail korechi dekhno pdf ta thik ache?\n",
        "Kiser?\n",
        "Fee payment üòÇ\n",
        "Ha thik a6e shudu chul gulo besi ure gia6e\n",
        "ü•≤ü•≤ü•≤\n",
        "Ager photo pali nai\n",
        "<Media omitted>\n",
        "You deleted this message\n",
        "<Media omitted>\n",
        "Vill-KECHARKUR, DIST- SOUTH 24 PGS, PIN-743395\n",
        "https://youtu.be/rKv98tE4De8\n",
        "<Media omitted>\n",
        "https://www.figma.com/community/file/1202113647978083142\n",
        "Bol\n",
        "Biswjit library asbe ki?\n",
        "Na\n",
        "Ok\n",
        "Ha\n",
        "Tui ki NSS er program e jabi?\n",
        "No\n",
        "Call korbi too argent\n",
        "Class e a6i\n",
        "Ok\n",
        "Ses hole koris\n",
        "Ami hostel e achi\n",
        "Quality ta bariye dis\n",
        "ok\n",
        "http://sakil.loogbyte.in/\n",
        "Eta 1080p dwanload kore dis\n",
        "This message was deleted\n",
        "eta 1080 dwanload kore dis to\n",
        "Dept te gia di66i\n",
        "Akhane net slow\n",
        "egulu baad diye r kichu bol\n",
        "Assignment ta hoye gele amake Patas too\n",
        "Amake korte hobe\n",
        "Ok\n",
        "16 september confirm karon tar age korle msc ra asbe na\n",
        "R 16 tarikh ta amader dada rao bolche so etai\n",
        "Ok\n",
        "Date conform kor\n",
        "Pore janabo dishani di k\n",
        "Ok\n",
        "eta dwanload kore de to 720 amar speed dichhe na\n",
        "Cl korbi to\n",
        "4 din age beria6e\n",
        "hm eta dekhlam ami kichuta valo ache\n",
        "ha\n",
        "3 number ta kore dibi too\n",
        "?\n",
        "??\n",
        "3 number ta dwanload kore de\n",
        "apply korbo ??\n",
        "Link ta open hoche koi\n",
        "khul6e to dhak ??\n",
        "but etar website e kichu nei\n",
        "dhakli ??\n",
        "apply korbo ki ??\n",
        "Hmm apply kore de\n",
        "tui ki korbi ??\n",
        "Korbo laptop\n",
        "‚òπÔ∏è‚òπÔ∏è resume nei\n",
        "Kor kotokhon time lagbe\n",
        "Faka time e lupin ta dekhbi mst ache\n",
        "Ok\n",
        "Bari jayar din dhakbo\n",
        "Ok\n",
        "Better luck next time üòî\n",
        "Tui apply korli ?\n",
        "Tui korle peye jabi\n",
        "Na kori nai vule gechli\n",
        "Resume korli\n",
        "Ha ota dheke dei ni\n",
        "Dekha\n",
        "R 200 taka de too recharge korbo r add kore dis taka ta\n",
        "Barite 30000 taka dia6i re amr kache tmn taka nei\n",
        "Bujli\n",
        "Ok ami  onno karo kache nichhi\n",
        "Tor mouse ta without keyboard e neoya jabe?\n",
        "Na\n",
        "Onno kono\n",
        "Ha\n",
        "Jomi er Record online e bar kora jai naki?\n",
        " Hmm record kora thakle copy ber kora jabe\n",
        " Ki kore?\n",
        " Ar atar kono hard copy dei naki?\n",
        " Taka pay korte Hobe tahole pabi\n",
        " Plot or khotiyan number ki ache?\n",
        " Jani na\n",
        " Dolil e dekhbi lekha ache\n",
        " Ok\n",
        " ei suru korechi ami\n",
        " Bhh\n",
        " Loki Somoy Rokshok\n",
        " Bol6i tor room er chabi ki amader room e\n",
        " ?\n",
        " Ami 20 tarikh train e uthte parbo na\n",
        "Amr mejdar dengue hoye6e\n",
        " Bari theke aktu deri kore jete bol6e\n",
        "Hm\n",
        " Tao Kobe parbi\n",
        " Tui ja 20 tarikh dorker hole lock veye dis\n",
        " Ok\n",
        " null\n",
        " Tui ekta link patha too key unlock korar\n",
        " Dhak kichu bujte Paris ki na\n",
        " null\n",
        " Bhh\n",
        " Beta\n",
        " Ektu side e ghurte gechilam üòÇ\n",
        " Bhh\n",
        " 2 jon?\n",
        " üòî R EKJON ACHE BUT ALADA BIKE\n",
        " Ooo\n",
        " Bishal baper too\n",
        " Hm\n",
        " Bhh\n",
        " Call korbo? Basto a6is?\n",
        " null\n",
        " Faltu bothe anty virus amar 3 yr chilo quick heal\n",
        " Oo\n",
        " Ok\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "J1D42emD32Ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "KhtDxwL_AXFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "K8MRFre9AaG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "TMIQITCT2Xn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrpAl3EDAgvh",
        "outputId": "ac8db5c3-685a-447c-c720-10cd1e2c2d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "292"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sentence in faqs.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "44VahqKdAjr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyqwPDzNA5mR",
        "outputId": "e5c48840-9456-4cea-84c0-7869b3257d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[79, 35],\n",
              " [79, 35, 80],\n",
              " [79, 35, 80, 81],\n",
              " [79, 35, 80, 81, 3],\n",
              " [79, 35, 80, 81, 3, 36],\n",
              " [79, 35, 80, 81, 3, 36, 7],\n",
              " [83, 84],\n",
              " [83, 84, 37],\n",
              " [10, 36],\n",
              " [10, 36, 85],\n",
              " [10, 36, 85, 86],\n",
              " [10, 36, 85, 86, 87],\n",
              " [10, 36, 85, 86, 87, 88],\n",
              " [10, 36, 85, 86, 87, 88, 89],\n",
              " [10, 36, 85, 86, 87, 88, 89, 90],\n",
              " [10, 36, 85, 86, 87, 88, 89, 90, 91],\n",
              " [93, 94],\n",
              " [93, 94, 95],\n",
              " [93, 94, 95, 38],\n",
              " [22, 23],\n",
              " [96, 39],\n",
              " [96, 39, 40],\n",
              " [96, 39, 40, 41],\n",
              " [22, 23],\n",
              " [97, 98],\n",
              " [97, 98, 99],\n",
              " [97, 98, 99, 100],\n",
              " [97, 98, 99, 100, 101],\n",
              " [97, 98, 99, 100, 101, 102],\n",
              " [97, 98, 99, 100, 101, 102, 103],\n",
              " [97, 98, 99, 100, 101, 102, 103, 104],\n",
              " [42, 105],\n",
              " [42, 105, 106],\n",
              " [42, 105, 106, 107],\n",
              " [22, 23],\n",
              " [42, 108],\n",
              " [42, 108, 109],\n",
              " [42, 108, 109, 110],\n",
              " [42, 108, 109, 110, 111],\n",
              " [42, 108, 109, 110, 111, 112],\n",
              " [42, 108, 109, 110, 111, 112, 113],\n",
              " [114, 115],\n",
              " [114, 115, 44],\n",
              " [114, 115, 44, 5],\n",
              " [8, 5],\n",
              " [8, 5, 116],\n",
              " [8, 5, 116, 24],\n",
              " [8, 5, 116, 24, 117],\n",
              " [8, 5, 116, 24, 117, 2],\n",
              " [8, 5, 116, 24, 117, 2, 45],\n",
              " [46, 25],\n",
              " [46, 25, 9],\n",
              " [46, 25, 9, 119],\n",
              " [120, 2],\n",
              " [120, 2, 121],\n",
              " [122, 47],\n",
              " [122, 47, 123],\n",
              " [11, 124],\n",
              " [11, 124, 2],\n",
              " [11, 124, 2, 125],\n",
              " [126, 3],\n",
              " [126, 3, 127],\n",
              " [126, 3, 127, 12],\n",
              " [128, 129],\n",
              " [128, 129, 130],\n",
              " [128, 129, 130, 131],\n",
              " [16, 132],\n",
              " [16, 132, 17],\n",
              " [16, 132, 17, 4],\n",
              " [16, 132, 17, 4, 12],\n",
              " [40, 41],\n",
              " [40, 41, 133],\n",
              " [40, 41, 133, 39],\n",
              " [16, 134],\n",
              " [16, 134, 17],\n",
              " [16, 134, 17, 4],\n",
              " [16, 134, 17, 4, 12],\n",
              " [16, 134, 17, 4, 12, 18],\n",
              " [135, 136],\n",
              " [135, 136, 137],\n",
              " [135, 136, 137, 138],\n",
              " [139, 140],\n",
              " [139, 140, 141],\n",
              " [142, 143],\n",
              " [142, 143, 144],\n",
              " [142, 143, 144, 13],\n",
              " [142, 143, 144, 13, 26],\n",
              " [142, 143, 144, 13, 26, 43],\n",
              " [145, 3],\n",
              " [145, 3, 146],\n",
              " [145, 3, 146, 147],\n",
              " [145, 3, 146, 147, 48],\n",
              " [145, 3, 146, 147, 48, 148],\n",
              " [145, 3, 146, 147, 48, 148, 9],\n",
              " [48, 49],\n",
              " [48, 49, 50],\n",
              " [51, 149],\n",
              " [51, 149, 150],\n",
              " [51, 149, 150, 151],\n",
              " [51, 149, 150, 151, 152],\n",
              " [51, 149, 150, 151, 152, 52],\n",
              " [51, 149, 150, 151, 152, 52, 53],\n",
              " [51, 149, 150, 151, 152, 52, 53, 153],\n",
              " [51, 149, 150, 151, 152, 52, 53, 153, 154],\n",
              " [51, 149, 150, 151, 152, 52, 53, 153, 154, 44],\n",
              " [51, 149, 150, 151, 152, 52, 53, 153, 154, 44, 6],\n",
              " [13, 51],\n",
              " [13, 51, 27],\n",
              " [13, 51, 27, 3],\n",
              " [13, 51, 27, 3, 54],\n",
              " [13, 51, 27, 3, 54, 155],\n",
              " [13, 51, 27, 3, 54, 155, 156],\n",
              " [13, 51, 27, 3, 54, 155, 156, 157],\n",
              " [13, 51, 27, 3, 54, 155, 156, 157, 158],\n",
              " [13, 51, 27, 3, 54, 155, 156, 157, 158, 159],\n",
              " [160, 161],\n",
              " [160, 161, 55],\n",
              " [162, 163],\n",
              " [162, 163, 164],\n",
              " [162, 163, 164, 165],\n",
              " [162, 163, 164, 165, 166],\n",
              " [16, 17],\n",
              " [16, 17, 4],\n",
              " [16, 17, 4, 19],\n",
              " [16, 17, 4, 19, 18],\n",
              " [16, 17, 4, 19, 18, 167],\n",
              " [16, 17, 4, 19, 18, 167, 56],\n",
              " [16, 17, 4, 19, 18, 167, 56, 168],\n",
              " [16, 17, 4, 19, 18, 167, 56, 168, 169],\n",
              " [16, 17, 4, 19, 18, 167, 56, 168, 169, 6],\n",
              " [170, 25],\n",
              " [170, 25, 18],\n",
              " [171, 57],\n",
              " [171, 57, 52],\n",
              " [171, 57, 52, 172],\n",
              " [28, 16],\n",
              " [28, 16, 173],\n",
              " [28, 16, 173, 11],\n",
              " [28, 16, 173, 11, 174],\n",
              " [28, 16, 173, 11, 174, 175],\n",
              " [28, 16, 173, 11, 174, 175, 7],\n",
              " [29, 30],\n",
              " [29, 30, 3],\n",
              " [29, 30, 3, 4],\n",
              " [29, 30, 3, 4, 176],\n",
              " [29, 30, 3, 4, 176, 9],\n",
              " [29, 30],\n",
              " [29, 30, 3],\n",
              " [29, 30, 3, 17],\n",
              " [29, 30, 3, 17, 4],\n",
              " [29, 30, 3, 17, 4, 19],\n",
              " [20, 14],\n",
              " [58, 3],\n",
              " [58, 3, 177],\n",
              " [58, 3, 177, 178],\n",
              " [58, 3, 177, 178, 179],\n",
              " [180, 18],\n",
              " [180, 18, 59],\n",
              " [60, 181],\n",
              " [60, 181, 182],\n",
              " [60, 181, 182, 2],\n",
              " [60, 181, 182, 2, 26],\n",
              " [60, 181, 182, 2, 26, 31],\n",
              " [20, 14],\n",
              " [20, 14, 5],\n",
              " [61, 20],\n",
              " [61, 20, 4],\n",
              " [61, 20, 4, 19],\n",
              " [8, 5],\n",
              " [8, 5, 25],\n",
              " [14, 184],\n",
              " [185, 62],\n",
              " [185, 62, 31],\n",
              " [55, 186],\n",
              " [55, 186, 32],\n",
              " [55, 186, 32, 187],\n",
              " [188, 32],\n",
              " [188, 32, 2],\n",
              " [188, 32, 2, 189],\n",
              " [188, 32, 2, 189, 3],\n",
              " [188, 32, 2, 189, 3, 63],\n",
              " [188, 32, 2, 189, 3, 63, 190],\n",
              " [188, 32, 2, 189, 3, 63, 190, 7],\n",
              " [64, 191],\n",
              " [64, 191, 57],\n",
              " [64, 191, 57, 192],\n",
              " [193, 194],\n",
              " [193, 194, 195],\n",
              " [193, 194, 195, 32],\n",
              " [193, 194, 195, 32, 65],\n",
              " [8, 20],\n",
              " [8, 20, 66],\n",
              " [8, 53],\n",
              " [8, 53, 196],\n",
              " [8, 53, 196, 45],\n",
              " [6, 197],\n",
              " [6, 197, 38],\n",
              " [6, 197, 38, 198],\n",
              " [6, 197, 38, 198, 199],\n",
              " [62, 66],\n",
              " [10, 200],\n",
              " [10, 200, 201],\n",
              " [10, 200, 201, 67],\n",
              " [10, 200, 201, 67, 202],\n",
              " [13, 204],\n",
              " [13, 204, 15],\n",
              " [13, 204, 15, 19],\n",
              " [13, 204, 15, 19, 9],\n",
              " [13, 204, 15, 19, 9, 205],\n",
              " [13, 204, 15, 19, 9, 205, 14],\n",
              " [13, 204, 15, 19, 9, 205, 14, 13],\n",
              " [13, 204, 15, 19, 9, 205, 14, 13, 206],\n",
              " [13, 204, 15, 19, 9, 205, 14, 13, 206, 4],\n",
              " [13, 204, 15, 19, 9, 205, 14, 13, 206, 4, 12],\n",
              " [13, 204, 15, 19, 9, 205, 14, 13, 206, 4, 12, 15],\n",
              " [13, 204, 15, 19, 9, 205, 14, 13, 206, 4, 12, 15, 3],\n",
              " [207, 208],\n",
              " [207, 208, 15],\n",
              " [207, 208, 15, 209],\n",
              " [207, 208, 15, 209, 210],\n",
              " [207, 208, 15, 209, 210, 68],\n",
              " [207, 208, 15, 209, 210, 68, 69],\n",
              " [207, 208, 15, 209, 210, 68, 69, 211],\n",
              " [207, 208, 15, 209, 210, 68, 69, 211, 15],\n",
              " [207, 208, 15, 209, 210, 68, 69, 211, 15, 31],\n",
              " [1, 11],\n",
              " [1, 11, 70],\n",
              " [1, 11, 70, 213],\n",
              " [1, 11, 70, 213, 69],\n",
              " [1, 11, 70, 213, 69, 214],\n",
              " [71, 215],\n",
              " [71, 215, 3],\n",
              " [71, 215, 3, 216],\n",
              " [71, 215, 3, 216, 217],\n",
              " [71, 215, 3, 216, 217, 2],\n",
              " [71, 215, 3, 216, 217, 2, 218],\n",
              " [71, 215, 3, 216, 217, 2, 218, 72],\n",
              " [70, 73],\n",
              " [219, 24],\n",
              " [219, 24, 74],\n",
              " [219, 24, 74, 220],\n",
              " [219, 24, 74, 220, 2],\n",
              " [219, 24, 74, 220, 2, 221],\n",
              " [219, 24, 74, 220, 2, 221, 33],\n",
              " [219, 24, 74, 220, 2, 221, 33, 222],\n",
              " [219, 24, 74, 220, 2, 221, 33, 222, 75],\n",
              " [61, 74],\n",
              " [61, 74, 33],\n",
              " [61, 74, 33, 223],\n",
              " [61, 74, 33, 223, 76],\n",
              " [61, 74, 33, 223, 76, 224],\n",
              " [61, 74, 33, 223, 76, 224, 33],\n",
              " [61, 74, 33, 223, 76, 224, 33, 72],\n",
              " [5, 4],\n",
              " [225, 226],\n",
              " [225, 226, 73],\n",
              " [225, 226, 73, 227],\n",
              " [225, 226, 73, 227, 76],\n",
              " [225, 226, 73, 227, 76, 67],\n",
              " [225, 226, 73, 227, 76, 67, 75],\n",
              " [15, 228],\n",
              " [15, 228, 49],\n",
              " [15, 228, 49, 50],\n",
              " [15, 228, 49, 50, 229],\n",
              " [15, 228, 49, 50, 229, 230],\n",
              " [231, 232],\n",
              " [231, 232, 233],\n",
              " [231, 232, 233, 30],\n",
              " [231, 232, 233, 30, 5],\n",
              " [231, 232, 233, 30, 5, 7],\n",
              " [234, 6],\n",
              " [235, 2],\n",
              " [235, 2, 63],\n",
              " [235, 2, 63, 236],\n",
              " [235, 2, 63, 236, 7],\n",
              " [237, 238],\n",
              " [237, 238, 35],\n",
              " [237, 238, 35, 11],\n",
              " [239, 240],\n",
              " [239, 240, 241],\n",
              " [242, 71],\n",
              " [242, 71, 77],\n",
              " [242, 71, 77, 24],\n",
              " [242, 71, 77, 24, 243],\n",
              " [242, 71, 77, 24, 243, 5],\n",
              " [242, 71, 77, 24, 243, 5, 54],\n",
              " [242, 71, 77, 24, 243, 5, 54, 77],\n",
              " [242, 71, 77, 24, 243, 5, 54, 77, 2],\n",
              " [11, 78],\n",
              " [11, 78, 27],\n",
              " [11, 78, 27, 244],\n",
              " [11, 78, 27, 244, 2],\n",
              " [11, 78, 27, 244, 2, 245],\n",
              " [11, 78, 27, 244, 2, 245, 246],\n",
              " [11, 78, 27, 244, 2, 245, 246, 6],\n",
              " [68, 247],\n",
              " [68, 247, 248],\n",
              " [68, 247, 248, 249],\n",
              " [64, 250],\n",
              " [64, 250, 251],\n",
              " [64, 250, 251, 252],\n",
              " [64, 250, 251, 252, 4],\n",
              " [64, 250, 251, 252, 4, 253],\n",
              " [64, 250, 251, 252, 4, 253, 254],\n",
              " [255, 256],\n",
              " [255, 256, 257],\n",
              " [8, 258],\n",
              " [8, 258, 78],\n",
              " [8, 258, 78, 27],\n",
              " [8, 258, 78, 27, 259],\n",
              " [8, 258, 78, 27, 259, 47],\n",
              " [8, 258, 78, 27, 259, 47, 260],\n",
              " [8, 258, 78, 27, 259, 47, 260, 261],\n",
              " [8, 258, 78, 27, 259, 47, 260, 261, 12],\n",
              " [8, 262],\n",
              " [8, 262, 58],\n",
              " [8, 262, 58, 263],\n",
              " [8, 262, 58, 263, 9],\n",
              " [8, 262, 58, 263, 9, 264],\n",
              " [8, 262, 58, 263, 9, 264, 265],\n",
              " [8, 262, 58, 263, 9, 264, 265, 266],\n",
              " [59, 26],\n",
              " [59, 26, 267],\n",
              " [59, 26, 267, 268],\n",
              " [59, 26, 267, 268, 5],\n",
              " [59, 26, 267, 268, 5, 6],\n",
              " [270, 271],\n",
              " [270, 271, 2],\n",
              " [270, 271, 2, 272],\n",
              " [270, 271, 2, 272, 273],\n",
              " [270, 271, 2, 272, 273, 37],\n",
              " [274, 275],\n",
              " [65, 13],\n",
              " [65, 13, 276],\n",
              " [65, 13, 276, 7],\n",
              " [65, 13, 276, 7, 60],\n",
              " [65, 13, 276, 7, 60, 277],\n",
              " [65, 13, 276, 7, 60, 277, 278],\n",
              " [280, 281],\n",
              " [280, 281, 9],\n",
              " [46, 14],\n",
              " [46, 14, 282],\n",
              " [46, 14, 282, 283],\n",
              " [284, 285],\n",
              " [284, 285, 286],\n",
              " [284, 285, 286, 287],\n",
              " [284, 285, 286, 287, 56],\n",
              " [284, 285, 286, 287, 56, 29],\n",
              " [284, 285, 286, 287, 56, 29, 288],\n",
              " [284, 285, 286, 287, 56, 29, 288, 289],\n",
              " [284, 285, 286, 287, 56, 29, 288, 289, 290],\n",
              " [284, 285, 286, 287, 56, 29, 288, 289, 290, 291]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "CrzbvUUQCXPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
      ],
      "metadata": {
        "id": "9oPMoWBSD1_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miRb-QZyIi7_",
        "outputId": "e8c81c81-9d96-443a-bf22-e6ab3f9737bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  79,  35],\n",
              "       [  0,   0,   0, ...,  79,  35,  80],\n",
              "       [  0,   0,   0, ...,  35,  80,  81],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,  29, 288, 289],\n",
              "       [  0,   0,   0, ..., 288, 289, 290],\n",
              "       [  0,   0,   0, ..., 289, 290, 291]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_input_sequences[:,:-1]"
      ],
      "metadata": {
        "id": "qVI0-UUrIsd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "lXrYHTDFI3uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmsFnHx1Qdow",
        "outputId": "747d3694-332f-4fa1-9c38-8c090246610d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(352, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wyYqYgZSeck",
        "outputId": "2eaee940-b936-43bd-9bca-0ff42ad4f59a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(352,)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes=num_words)"
      ],
      "metadata": {
        "id": "rs1NPitwSgzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQMJ0I6xSiZf",
        "outputId": "1e964ace-fe5d-4011-b085-ccc33e791cf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(352, 293)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "9kVeTvR2S8Fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "lstm_units = 150\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words, embedding_dim, input_length=max_len - 1))\n",
        "model.add(LSTM(lstm_units, return_sequences=True))\n",
        "model.add(LSTM(lstm_units))\n",
        "model.add(Dense(num_words, activation='softmax'))"
      ],
      "metadata": {
        "id": "wo-OYfHpTK2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-GGjqh7ue_Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxxXkrSXfIBv",
        "outputId": "31f445f6-cbfe-447d-93e6-fb5aed6bcc48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 12, 100)           29300     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 12, 150)           150600    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 150)               180600    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 293)               44243     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 404743 (1.54 MB)\n",
            "Trainable params: 404743 (1.54 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "mbWfuhJ687P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpFUCALCfJRR",
        "outputId": "16e916af-2590-410f-905c-09bfb7771f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 5s 57ms/step - loss: 5.6770 - accuracy: 0.0256\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 5.5704 - accuracy: 0.0312\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 5.4155 - accuracy: 0.0199\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 5.3289 - accuracy: 0.0312\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 5.2951 - accuracy: 0.0227\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 1s 101ms/step - loss: 5.2753 - accuracy: 0.0284\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 5.2644 - accuracy: 0.0312\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 5.2464 - accuracy: 0.0341\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 5.2236 - accuracy: 0.0341\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 5.1931 - accuracy: 0.0369\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 5.1358 - accuracy: 0.0398\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 5.0607 - accuracy: 0.0341\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 4.9598 - accuracy: 0.0398\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 4.8549 - accuracy: 0.0511\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 4.7442 - accuracy: 0.0568\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 4.6380 - accuracy: 0.0483\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 4.5114 - accuracy: 0.0511\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 4.4142 - accuracy: 0.0483\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 4.3092 - accuracy: 0.0739\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 4.1909 - accuracy: 0.0938\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 4.0891 - accuracy: 0.0881\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 4.0033 - accuracy: 0.1023\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 3.8981 - accuracy: 0.1278\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 3.7975 - accuracy: 0.1193\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 3.7124 - accuracy: 0.1420\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 3.6238 - accuracy: 0.1733\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 1s 102ms/step - loss: 3.5299 - accuracy: 0.1818\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 1s 101ms/step - loss: 3.4496 - accuracy: 0.2330\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 3.3777 - accuracy: 0.2188\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 1s 81ms/step - loss: 3.3107 - accuracy: 0.2415\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 3.2376 - accuracy: 0.2642\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 3.1704 - accuracy: 0.2642\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 3.1177 - accuracy: 0.2727\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 3.0600 - accuracy: 0.3210\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 2.9968 - accuracy: 0.3324\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 2.9206 - accuracy: 0.3494\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 2.8437 - accuracy: 0.3665\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 2.7676 - accuracy: 0.3949\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 2.7095 - accuracy: 0.3949\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 2.6343 - accuracy: 0.4176\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 2.5759 - accuracy: 0.4460\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 2.5321 - accuracy: 0.4261\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 2.4880 - accuracy: 0.4403\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 2.4295 - accuracy: 0.4744\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 2.3663 - accuracy: 0.4801\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 2.3113 - accuracy: 0.4943\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 2.2719 - accuracy: 0.5114\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 1s 99ms/step - loss: 2.2345 - accuracy: 0.5170\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 2.1835 - accuracy: 0.5142\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 2.1311 - accuracy: 0.5511\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 2.0816 - accuracy: 0.5682\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 2.0283 - accuracy: 0.5511\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 2.0005 - accuracy: 0.5682\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 1.9454 - accuracy: 0.6023\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 1.9069 - accuracy: 0.6080\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 1.8708 - accuracy: 0.6307\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 1.8163 - accuracy: 0.6392\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 1.7840 - accuracy: 0.6364\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 1.7450 - accuracy: 0.6449\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 1.7108 - accuracy: 0.6477\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 1.6679 - accuracy: 0.6676\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 1.6378 - accuracy: 0.6676\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 1.6083 - accuracy: 0.6818\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 1.5980 - accuracy: 0.6875\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 1.5643 - accuracy: 0.6847\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 1.5247 - accuracy: 0.7074\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 1.4851 - accuracy: 0.7216\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 1.4418 - accuracy: 0.7301\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 1.4064 - accuracy: 0.7386\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 1.3710 - accuracy: 0.7301\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 1.3445 - accuracy: 0.7330\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 1.3145 - accuracy: 0.7670\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 1.2938 - accuracy: 0.7557\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 1.2587 - accuracy: 0.7727\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 1.2315 - accuracy: 0.7869\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 1.2081 - accuracy: 0.7898\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 1.1821 - accuracy: 0.7955\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 1.1517 - accuracy: 0.8153\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 1.1240 - accuracy: 0.8040\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 1.0989 - accuracy: 0.8011\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 1.0798 - accuracy: 0.8125\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 1.0576 - accuracy: 0.8068\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 1.0357 - accuracy: 0.8125\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 1.0251 - accuracy: 0.8239\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 1.0041 - accuracy: 0.8295\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.9790 - accuracy: 0.8267\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.9653 - accuracy: 0.8438\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 1s 105ms/step - loss: 0.9363 - accuracy: 0.8466\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 1s 101ms/step - loss: 0.9114 - accuracy: 0.8494\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.8920 - accuracy: 0.8438\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 1s 85ms/step - loss: 0.8689 - accuracy: 0.8580\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.8515 - accuracy: 0.8494\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.8322 - accuracy: 0.8608\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.8206 - accuracy: 0.8636\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.7991 - accuracy: 0.8580\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.7807 - accuracy: 0.8750\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.7695 - accuracy: 0.8722\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.7529 - accuracy: 0.8949\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 0.7359 - accuracy: 0.8778\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.7228 - accuracy: 0.8750\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a5d94573c10>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "text = \"Tui\"\n",
        "\n",
        "for i in range(3):\n",
        "    token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "    padded_token_text = pad_sequences([token_text], maxlen=max_len - 1, padding='pre')\n",
        "    pos = np.argmax(model.predict(padded_token_text))\n",
        "    predicted_word = tokenizer.index_word[pos]\n",
        "    text = text + \" \" + predicted_word\n",
        "    print(text)\n",
        "    time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGeYGwCMfTus",
        "outputId": "fd3cf8b1-c684-4b2d-8b51-4f81bc42634e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "Tui ki\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Tui ki korbi\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Tui ki korbi too\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTxsj-_CjbQW",
        "outputId": "65934c9a-e9ec-4632-d4aa-34b00354f9a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ok': 1,\n",
              " 'e': 2,\n",
              " 'ta': 3,\n",
              " 'kore': 4,\n",
              " 'ki': 5,\n",
              " 'na': 6,\n",
              " 'ache': 7,\n",
              " 'tui': 8,\n",
              " 'too': 9,\n",
              " 'ha': 10,\n",
              " 'ami': 11,\n",
              " 'dis': 12,\n",
              " 'r': 13,\n",
              " 'korbo': 14,\n",
              " 'taka': 15,\n",
              " 'eta': 16,\n",
              " 'dwanload': 17,\n",
              " 'to': 18,\n",
              " 'de': 19,\n",
              " 'apply': 20,\n",
              " 'bhh': 21,\n",
              " 'media': 22,\n",
              " 'omitted': 23,\n",
              " 'er': 24,\n",
              " 'korbi': 25,\n",
              " 'kichu': 26,\n",
              " 'tarikh': 27,\n",
              " 'hm': 28,\n",
              " '3': 29,\n",
              " 'number': 30,\n",
              " 'nei': 31,\n",
              " 'time': 32,\n",
              " 'kora': 33,\n",
              " 'null': 34,\n",
              " 'korechi': 35,\n",
              " 'thik': 36,\n",
              " 'üòÇ': 37,\n",
              " 'nai': 38,\n",
              " 'deleted': 39,\n",
              " 'this': 40,\n",
              " 'message': 41,\n",
              " 'https': 42,\n",
              " 'bol': 43,\n",
              " 'asbe': 44,\n",
              " 'jabi': 45,\n",
              " 'call': 46,\n",
              " 'hole': 47,\n",
              " 'amake': 48,\n",
              " 'korte': 49,\n",
              " 'hobe': 50,\n",
              " '16': 51,\n",
              " 'age': 52,\n",
              " 'korle': 53,\n",
              " 'amader': 54,\n",
              " 'kor': 55,\n",
              " 'amar': 56,\n",
              " 'din': 57,\n",
              " 'link': 58,\n",
              " 'dhak': 59,\n",
              " 'but': 60,\n",
              " 'hmm': 61,\n",
              " 'resume': 62,\n",
              " 'dekhbi': 63,\n",
              " 'bari': 64,\n",
              " 'üòî': 65,\n",
              " 'korli': 66,\n",
              " 'dei': 67,\n",
              " 'amr': 68,\n",
              " 'kache': 69,\n",
              " 'onno': 70,\n",
              " 'tor': 71,\n",
              " 'jabe': 72,\n",
              " 'kono': 73,\n",
              " 'record': 74,\n",
              " 'naki': 75,\n",
              " 'copy': 76,\n",
              " 'room': 77,\n",
              " '20': 78,\n",
              " 'mail': 79,\n",
              " 'dekhno': 80,\n",
              " 'pdf': 81,\n",
              " 'kiser': 82,\n",
              " 'fee': 83,\n",
              " 'payment': 84,\n",
              " 'a6e': 85,\n",
              " 'shudu': 86,\n",
              " 'chul': 87,\n",
              " 'gulo': 88,\n",
              " 'besi': 89,\n",
              " 'ure': 90,\n",
              " 'gia6e': 91,\n",
              " 'ü•≤ü•≤ü•≤': 92,\n",
              " 'ager': 93,\n",
              " 'photo': 94,\n",
              " 'pali': 95,\n",
              " 'you': 96,\n",
              " 'vill': 97,\n",
              " 'kecharkur': 98,\n",
              " 'dist': 99,\n",
              " 'south': 100,\n",
              " '24': 101,\n",
              " 'pgs': 102,\n",
              " 'pin': 103,\n",
              " '743395': 104,\n",
              " 'youtu': 105,\n",
              " 'be': 106,\n",
              " 'rkv98te4de8': 107,\n",
              " 'www': 108,\n",
              " 'figma': 109,\n",
              " 'com': 110,\n",
              " 'community': 111,\n",
              " 'file': 112,\n",
              " '1202113647978083142': 113,\n",
              " 'biswjit': 114,\n",
              " 'library': 115,\n",
              " 'nss': 116,\n",
              " 'program': 117,\n",
              " 'no': 118,\n",
              " 'argent': 119,\n",
              " 'class': 120,\n",
              " 'a6i': 121,\n",
              " 'ses': 122,\n",
              " 'koris': 123,\n",
              " 'hostel': 124,\n",
              " 'achi': 125,\n",
              " 'quality': 126,\n",
              " 'bariye': 127,\n",
              " 'http': 128,\n",
              " 'sakil': 129,\n",
              " 'loogbyte': 130,\n",
              " 'in': 131,\n",
              " '1080p': 132,\n",
              " 'was': 133,\n",
              " '1080': 134,\n",
              " 'dept': 135,\n",
              " 'te': 136,\n",
              " 'gia': 137,\n",
              " 'di66i': 138,\n",
              " 'akhane': 139,\n",
              " 'net': 140,\n",
              " 'slow': 141,\n",
              " 'egulu': 142,\n",
              " 'baad': 143,\n",
              " 'diye': 144,\n",
              " 'assignment': 145,\n",
              " 'hoye': 146,\n",
              " 'gele': 147,\n",
              " 'patas': 148,\n",
              " 'september': 149,\n",
              " 'confirm': 150,\n",
              " 'karon': 151,\n",
              " 'tar': 152,\n",
              " 'msc': 153,\n",
              " 'ra': 154,\n",
              " 'dada': 155,\n",
              " 'rao': 156,\n",
              " 'bolche': 157,\n",
              " 'so': 158,\n",
              " 'etai': 159,\n",
              " 'date': 160,\n",
              " 'conform': 161,\n",
              " 'pore': 162,\n",
              " 'janabo': 163,\n",
              " 'dishani': 164,\n",
              " 'di': 165,\n",
              " 'k': 166,\n",
              " '720': 167,\n",
              " 'speed': 168,\n",
              " 'dichhe': 169,\n",
              " 'cl': 170,\n",
              " '4': 171,\n",
              " 'beria6e': 172,\n",
              " 'dekhlam': 173,\n",
              " 'kichuta': 174,\n",
              " 'valo': 175,\n",
              " 'dibi': 176,\n",
              " 'open': 177,\n",
              " 'hoche': 178,\n",
              " 'koi': 179,\n",
              " 'khul6e': 180,\n",
              " 'etar': 181,\n",
              " 'website': 182,\n",
              " 'dhakli': 183,\n",
              " 'laptop': 184,\n",
              " '‚òπÔ∏è‚òπÔ∏è': 185,\n",
              " 'kotokhon': 186,\n",
              " 'lagbe': 187,\n",
              " 'faka': 188,\n",
              " 'lupin': 189,\n",
              " 'mst': 190,\n",
              " 'jayar': 191,\n",
              " 'dhakbo': 192,\n",
              " 'better': 193,\n",
              " 'luck': 194,\n",
              " 'next': 195,\n",
              " 'peye': 196,\n",
              " 'kori': 197,\n",
              " 'vule': 198,\n",
              " 'gechli': 199,\n",
              " 'ota': 200,\n",
              " 'dheke': 201,\n",
              " 'ni': 202,\n",
              " 'dekha': 203,\n",
              " '200': 204,\n",
              " 'recharge': 205,\n",
              " 'add': 206,\n",
              " 'barite': 207,\n",
              " '30000': 208,\n",
              " 'dia6i': 209,\n",
              " 're': 210,\n",
              " 'tmn': 211,\n",
              " 'bujli': 212,\n",
              " 'karo': 213,\n",
              " 'nichhi': 214,\n",
              " 'mouse': 215,\n",
              " 'without': 216,\n",
              " 'keyboard': 217,\n",
              " 'neoya': 218,\n",
              " 'jomi': 219,\n",
              " 'online': 220,\n",
              " 'bar': 221,\n",
              " 'jai': 222,\n",
              " 'thakle': 223,\n",
              " 'ber': 224,\n",
              " 'ar': 225,\n",
              " 'atar': 226,\n",
              " 'hard': 227,\n",
              " 'pay': 228,\n",
              " 'tahole': 229,\n",
              " 'pabi': 230,\n",
              " 'plot': 231,\n",
              " 'or': 232,\n",
              " 'khotiyan': 233,\n",
              " 'jani': 234,\n",
              " 'dolil': 235,\n",
              " 'lekha': 236,\n",
              " 'ei': 237,\n",
              " 'suru': 238,\n",
              " 'loki': 239,\n",
              " 'somoy': 240,\n",
              " 'rokshok': 241,\n",
              " 'bol6i': 242,\n",
              " 'chabi': 243,\n",
              " 'train': 244,\n",
              " 'uthte': 245,\n",
              " 'parbo': 246,\n",
              " 'mejdar': 247,\n",
              " 'dengue': 248,\n",
              " 'hoye6e': 249,\n",
              " 'theke': 250,\n",
              " 'aktu': 251,\n",
              " 'deri': 252,\n",
              " 'jete': 253,\n",
              " 'bol6e': 254,\n",
              " 'tao': 255,\n",
              " 'kobe': 256,\n",
              " 'parbi': 257,\n",
              " 'ja': 258,\n",
              " 'dorker': 259,\n",
              " 'lock': 260,\n",
              " 'veye': 261,\n",
              " 'ekta': 262,\n",
              " 'patha': 263,\n",
              " 'key': 264,\n",
              " 'unlock': 265,\n",
              " 'korar': 266,\n",
              " 'bujte': 267,\n",
              " 'paris': 268,\n",
              " 'beta': 269,\n",
              " 'ektu': 270,\n",
              " 'side': 271,\n",
              " 'ghurte': 272,\n",
              " 'gechilam': 273,\n",
              " '2': 274,\n",
              " 'jon': 275,\n",
              " 'ekjon': 276,\n",
              " 'alada': 277,\n",
              " 'bike': 278,\n",
              " 'ooo': 279,\n",
              " 'bishal': 280,\n",
              " 'baper': 281,\n",
              " 'basto': 282,\n",
              " 'a6is': 283,\n",
              " 'faltu': 284,\n",
              " 'bothe': 285,\n",
              " 'anty': 286,\n",
              " 'virus': 287,\n",
              " 'yr': 288,\n",
              " 'chilo': 289,\n",
              " 'quick': 290,\n",
              " 'heal': 291,\n",
              " 'oo': 292}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}